{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Champei/mine/blob/main/chapter_appendix-tools-for-deep-learning/jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "zRrt2PRttT2Y",
        "outputId": "c8493c49-031b-4781-cbbb-2e1f3d9edd2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zRrt2PRttT2Y",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/\"Colab Notebooks\"\n",
        "\n"
      ],
      "metadata": {
        "id": "396foA59taLB",
        "outputId": "5dcd8605-7a6a-48e2-ee93-0f3332a6fd47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "396foA59taLB",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jupyter\n",
        "!jupyter nbconvert --to script \"RAG.ipynb\"\n"
      ],
      "metadata": {
        "id": "FDkNJhMXtlgX",
        "outputId": "a561da0e-8e8e-4d50-c9a5-1d1765662659",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FDkNJhMXtlgX",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jupyter\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from jupyter) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter) (6.6.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from jupyter) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from jupyter) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from jupyter) (7.7.1)\n",
            "Collecting jupyterlab (from jupyter)\n",
            "  Downloading jupyterlab-4.4.10-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter) (3.0.15)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from jupyter-console->jupyter) (5.9.1)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.30 in /usr/local/lib/python3.12/dist-packages (from jupyter-console->jupyter) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from jupyter-console->jupyter) (2.19.2)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter) (3.1.6)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
            "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter) (2.14.0)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter)\n",
            "  Downloading jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter) (0.2.4)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter) (75.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (3.0.3)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (25.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter) (1.3.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.9.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-console->jupyter) (4.5.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.9.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook->jupyter) (25.1.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
            "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.25.1)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.14)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.12/dist-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->jupyter) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->jupyter) (4.15.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.28.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->jupyter) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.5.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.23)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.4.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2025.2)\n",
            "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading jupyterlab-4.4.10-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: json5, jedi, async-lru, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter\n",
            "Successfully installed async-lru-2.0.5 jedi-0.19.2 json5-0.12.1 jupyter-1.1.1 jupyter-lsp-2.3.0 jupyterlab-4.4.10 jupyterlab-server-2.28.0\n",
            "[NbConvertApp] Converting notebook RAG.ipynb to script\n",
            "[NbConvertApp] Writing 17789 bytes to RAG.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "\n"
      ],
      "metadata": {
        "id": "TqEWpYc3uIcR",
        "outputId": "91fe81c7-deb7-4249-d660-e53f700e938e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TqEWpYc3uIcR",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " audio_classification.ipynb  'Copy of jupyter.ipynb'\t  Untitled\n",
            "'Copy of audo.ipynb'\t     'Copy of MNIST.ipynb'\t  Untitled0.ipynb\n",
            "'Copy of jupyter (1).ipynb'  'Copy of Welcome to Colab'  'Untitled (1)'\n",
            "'Copy of jupyter (2).ipynb'   RAG.ipynb\t\t\t  Untitled1.ipynb\n",
            "'Copy of jupyter (3).ipynb'   RAG.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"rag_chatbot.py\", \"w\") as f:\n",
        "    f.write('''<PASTE THE FULL CODE FROM YOUR NOTEBOOK HERE>''')\n"
      ],
      "metadata": {
        "id": "yeYoHa_nuOW5"
      },
      "id": "yeYoHa_nuOW5",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "G3sFk1MIvHeT",
        "outputId": "a08aea51-8fd9-402d-8a96-1ce5617fe2f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "G3sFk1MIvHeT",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " audio_classification.ipynb  'Copy of jupyter.ipynb'\t  RAG.txt\n",
            "'Copy of audo.ipynb'\t     'Copy of MNIST.ipynb'\t  Untitled\n",
            "'Copy of jupyter (1).ipynb'  'Copy of Welcome to Colab'   Untitled0.ipynb\n",
            "'Copy of jupyter (2).ipynb'   rag_chatbot.py\t\t 'Untitled (1)'\n",
            "'Copy of jupyter (3).ipynb'   RAG.ipynb\t\t\t  Untitled1.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from rag_chatbot import DocumentStore, Generator, MemoryManager, RAGPipeline, ingest_folder_texts\n",
        "\n",
        "st.set_page_config(page_title=\"RAG Chatbot\", layout=\"wide\")\n",
        "st.title(\"ğŸ’¬ Retrieval-Augmented Chatbot\")\n",
        "\n",
        "st.sidebar.header(\"âš™ï¸ Settings\")\n",
        "mode = st.sidebar.radio(\"Generator Mode\", [\"openai\", \"local\"])\n",
        "top_k = st.sidebar.slider(\"Top-K retrieved chunks\", 2, 10, 4)\n",
        "max_turns = st.sidebar.slider(\"Memory turns\", 2, 10, 6)\n",
        "\n",
        "@st.cache_resource\n",
        "def init_pipeline(mode, top_k, max_turns):\n",
        "    store = DocumentStore(persist_path=\"./rag_store\")\n",
        "    ingest_folder_texts(\"corpus\", store)\n",
        "    gen = Generator(mode=mode)\n",
        "    mem = MemoryManager(max_turns=max_turns)\n",
        "    return RAGPipeline(store=store, generator=gen, memory=mem, top_k=top_k)\n",
        "\n",
        "rag = init_pipeline(mode, top_k, max_turns)\n",
        "\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state[\"chat_history\"] = []\n",
        "\n",
        "for turn in st.session_state[\"chat_history\"]:\n",
        "    with st.chat_message(turn[\"role\"]):\n",
        "        st.markdown(turn[\"content\"])\n",
        "\n",
        "user_query = st.chat_input(\"Ask a question...\")\n",
        "\n",
        "if user_query:\n",
        "    st.session_state[\"chat_history\"].append({\"role\": \"user\", \"content\": user_query})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(user_query)\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        with st.spinner(\"Thinking...\"):\n",
        "            response = rag.answer(user_query)\n",
        "        answer = response.get(\"clarification\") if response.get(\"clarify\") else response[\"answer\"]\n",
        "        st.markdown(answer)\n",
        "        if not response.get(\"clarify\") and response.get(\"citations\"):\n",
        "            with st.expander(\" Sources and Citations\"):\n",
        "                for c in response[\"citations\"]:\n",
        "                    st.markdown(f\"**[{c['rank']}]** {c['source_id']} â€” *score: {c['score']:.4f}*\")\n",
        "                    st.caption(c[\"snippet\"])\n",
        "    st.session_state[\"chat_history\"].append({\"role\": \"assistant\", \"content\": answer})\n"
      ],
      "metadata": {
        "id": "thhvRrI6vJ1o",
        "outputId": "dbd95b89-6ea0-4bb5-9411-fa55f73f477e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "thhvRrI6vJ1o",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers faiss-cpu numpy transformers torch openai streamlit pyngrok\n"
      ],
      "metadata": {
        "id": "CLeaJpeOvPhx",
        "outputId": "b8f005c2-185e-4b22-8d91-417bbd51cb03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CLeaJpeOvPhx",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.4.1-py3-none-any.whl (25 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyngrok, faiss-cpu, pydeck, streamlit\n",
            "Successfully installed faiss-cpu-1.12.0 pydeck-0.9.1 pyngrok-7.4.1 streamlit-1.51.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 34nh4N2eC2z7X5obk1C986VYwQ3_4tRDysfSuBDzb182dtgqx\n"
      ],
      "metadata": {
        "id": "K2oxBicYvYNu",
        "outputId": "4c89e010-8e2a-4a28-ae56-9c3cc93a0d60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "K2oxBicYvYNu",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"rag_chatbot.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "import os, re, time, pickle, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "\n",
        "# Optional: OpenAI for generation\n",
        "try:\n",
        "    import openai\n",
        "    OPENAI_AVAILABLE = True\n",
        "except Exception:\n",
        "    OPENAI_AVAILABLE = False\n",
        "\n",
        "# Optional: local HF model for generation\n",
        "try:\n",
        "    from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "    HF_AVAILABLE = True\n",
        "except Exception:\n",
        "    HF_AVAILABLE = False\n",
        "\n",
        "# -----------------------\n",
        "# Utilities\n",
        "# -----------------------\n",
        "\n",
        "def simple_text_clean(text: str) -> str:\n",
        "    text = text.replace(\"\\\\r\", \" \").replace(\"\\\\n\", \" \").strip()\n",
        "    text = re.sub(r\"\\\\s+\", \" \", text)\n",
        "    return text\n",
        "\n",
        "def chunk_text(text: str, chunk_size: int = 800, overlap: int = 100) -> List[str]:\n",
        "    text = simple_text_clean(text)\n",
        "    if len(text) <= chunk_size:\n",
        "        return [text]\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = min(len(text), start + chunk_size)\n",
        "        chunk = text[start:end]\n",
        "        chunks.append(chunk)\n",
        "        if end == len(text):\n",
        "            break\n",
        "        start = max(0, end - overlap)\n",
        "    return chunks\n",
        "\n",
        "# -----------------------\n",
        "# Data classes\n",
        "# -----------------------\n",
        "\n",
        "@dataclass\n",
        "class DocChunk:\n",
        "    id: str\n",
        "    text: str\n",
        "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
        "    embedding: Optional[np.ndarray] = None\n",
        "\n",
        "# -----------------------\n",
        "# Document Store + Indexing\n",
        "# -----------------------\n",
        "\n",
        "class DocumentStore:\n",
        "    def __init__(self, embed_model_name: str = \"all-MiniLM-L6-v2\",\n",
        "                 faiss_index_path: Optional[str] = None,\n",
        "                 persist_path: Optional[str] = \"./rag_store\"):\n",
        "        self.embed_model_name = embed_model_name\n",
        "        self.embed_model = SentenceTransformer(embed_model_name)\n",
        "        self.dim = self.embed_model.get_sentence_embedding_dimension()\n",
        "        self.index = None\n",
        "        self.id_to_meta: Dict[str, Dict[str, Any]] = {}\n",
        "        self.embeddings = None\n",
        "        self.ids = []\n",
        "        self.persist_path = Path(persist_path)\n",
        "        self.persist_path.mkdir(parents=True, exist_ok=True)\n",
        "        self.faiss_index_path = faiss_index_path or (self.persist_path / \"faiss.index\")\n",
        "        self.meta_path = self.persist_path / \"metastore.pkl\"\n",
        "        if self.faiss_index_path.exists() and self.meta_path.exists():\n",
        "            self._load()\n",
        "\n",
        "    def _build_faiss(self, embeddings: np.ndarray):\n",
        "        index = faiss.IndexFlatIP(self.dim)\n",
        "        faiss.normalize_L2(embeddings)\n",
        "        index.add(embeddings)\n",
        "        self.index = index\n",
        "\n",
        "    def _save(self):\n",
        "        if self.index is None:\n",
        "            return\n",
        "        faiss.write_index(self.index, str(self.faiss_index_path))\n",
        "        with open(self.meta_path, \"wb\") as f:\n",
        "            pickle.dump({\"ids\": self.ids, \"id_to_meta\": self.id_to_meta}, f)\n",
        "\n",
        "    def _load(self):\n",
        "        idx = faiss.read_index(str(self.faiss_index_path))\n",
        "        self.index = idx\n",
        "        with open(self.meta_path, \"rb\") as f:\n",
        "            d = pickle.load(f)\n",
        "            self.ids = d[\"ids\"]\n",
        "            self.id_to_meta = d[\"id_to_meta\"]\n",
        "\n",
        "    def add_documents(self, docs: List[Tuple[str, str, Dict[str, Any]]],\n",
        "                      chunk_size: int = 800, chunk_overlap: int = 100):\n",
        "        chunks: List[DocChunk] = []\n",
        "        for doc_id, raw_text, meta in docs:\n",
        "            for i, c in enumerate(chunk_text(raw_text, chunk_size, chunk_overlap)):\n",
        "                cid = f\"{doc_id}__chunk{i}\"\n",
        "                chunks.append(DocChunk(id=cid, text=c, metadata={**meta, \"source_id\": doc_id, \"chunk_index\": i}))\n",
        "\n",
        "        if not chunks:\n",
        "            return\n",
        "\n",
        "        texts = [c.text for c in chunks]\n",
        "        embeddings = self.embed_model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
        "        faiss.normalize_L2(embeddings)\n",
        "\n",
        "        if self.index is None:\n",
        "            self.index = faiss.IndexFlatIP(self.dim)\n",
        "            self.index.add(embeddings)\n",
        "            self.ids = [c.id for c in chunks]\n",
        "            for c in chunks:\n",
        "                self.id_to_meta[c.id] = {\"text\": c.text, **c.metadata}\n",
        "        else:\n",
        "            self.index.add(embeddings)\n",
        "            self.ids.extend([c.id for c in chunks])\n",
        "            for c in chunks:\n",
        "                self.id_to_meta[c.id] = {\"text\": c.text, **c.metadata}\n",
        "        self._save()\n",
        "\n",
        "    def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:\n",
        "        q_emb = self.embed_model.encode([query], convert_to_numpy=True)\n",
        "        faiss.normalize_L2(q_emb)\n",
        "        if self.index is None or self.index.ntotal == 0:\n",
        "            return []\n",
        "        D, I = self.index.search(q_emb, top_k)\n",
        "        results = []\n",
        "        for score, idx in zip(D[0], I[0]):\n",
        "            if idx < 0 or idx >= len(self.ids):\n",
        "                continue\n",
        "            doc_id = self.ids[idx]\n",
        "            meta = self.id_to_meta.get(doc_id, {})\n",
        "            results.append({\n",
        "                \"id\": doc_id,\n",
        "                \"score\": float(score),\n",
        "                \"text\": meta.get(\"text\", \"\"),\n",
        "                \"metadata\": {k: v for k, v in meta.items() if k != \"text\"}\n",
        "            })\n",
        "        return results\n",
        "\n",
        "# -----------------------\n",
        "# Memory Manager\n",
        "# -----------------------\n",
        "\n",
        "class MemoryManager:\n",
        "    def __init__(self, max_turns: int = 6):\n",
        "        self.max_turns = max_turns\n",
        "        self.turns: List[Dict[str, Any]] = []\n",
        "\n",
        "    def add_turn(self, role: str, text: str, retrieved_docs: Optional[List[Dict]] = None):\n",
        "        import time\n",
        "        self.turns.append({\"role\": role, \"text\": text, \"time\": time.time(), \"retrieved_docs\": retrieved_docs or []})\n",
        "        if len(self.turns) > self.max_turns:\n",
        "            self.turns = self.turns[-self.max_turns:]\n",
        "\n",
        "    def get_memory_prompt(self) -> str:\n",
        "        if not self.turns:\n",
        "            return \"\"\n",
        "        return \"\\\\n\".join([f\"{t['role']}: {t['text']}\" for t in self.turns])\n",
        "\n",
        "# -----------------------\n",
        "# Generator\n",
        "# -----------------------\n",
        "\n",
        "class Generator:\n",
        "    def __init__(self, mode: str = \"openai\", openai_model: str = \"gpt-4o-mini\", hf_model_name: str = \"gpt2\"):\n",
        "        self.mode = mode\n",
        "        self.openai_model = openai_model\n",
        "        self.hf_model_name = hf_model_name\n",
        "        self.hf_pipe = None\n",
        "        if mode == \"openai\" and OPENAI_AVAILABLE:\n",
        "            openai.api_key = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
        "        if mode == \"local\" and HF_AVAILABLE:\n",
        "            try:\n",
        "                self.hf_pipe = pipeline(\"text-generation\", model=self.hf_model_name, device_map=\"auto\")\n",
        "            except Exception as e:\n",
        "                print(\"Failed to load HF model:\", e)\n",
        "\n",
        "    def generate(self, prompt: str, max_tokens: int = 512, temperature: float = 0.0) -> str:\n",
        "        if self.mode == \"openai\" and OPENAI_AVAILABLE:\n",
        "            resp = openai.ChatCompletion.create(\n",
        "                model=self.openai_model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=max_tokens,\n",
        "                temperature=temperature,\n",
        "                n=1\n",
        "            )\n",
        "            return resp.choices[0].message.content.strip()\n",
        "        elif self.mode == \"local\" and self.hf_pipe is not None:\n",
        "            out = self.hf_pipe(prompt, max_length=max_tokens + len(prompt.split()), do_sample=False)\n",
        "            return out[0][\"generated_text\"][len(prompt):].strip()\n",
        "        else:\n",
        "            return \"âš ï¸ No generator configured â€” set OPENAI_API_KEY or use HF model.\"\n",
        "\n",
        "# -----------------------\n",
        "# RAG Pipeline\n",
        "# -----------------------\n",
        "\n",
        "class RAGPipeline:\n",
        "    def __init__(self, store: DocumentStore, generator: Generator, memory: Optional[MemoryManager] = None, top_k: int = 4):\n",
        "        self.store = store\n",
        "        self.generator = generator\n",
        "        self.memory = memory or MemoryManager()\n",
        "        self.top_k = top_k\n",
        "\n",
        "    def _build_context_block(self, retrieved: List[Dict[str, Any]]) -> str:\n",
        "        parts = []\n",
        "        for i, r in enumerate(retrieved, start=1):\n",
        "            source = r[\"metadata\"].get(\"source_id\", r[\"id\"])\n",
        "            snippet = r[\"text\"][:600].strip()\n",
        "            parts.append(f\"[{i}] Source: {source} | Score: {r['score']:.4f}\\\\nSnippet: {snippet}\")\n",
        "        return \"\\\\n\\\\n\".join(parts)\n",
        "\n",
        "    def _build_prompt(self, user_query: str, retrieved: List[Dict[str, Any]]) -> str:\n",
        "        memory_block = self.memory.get_memory_prompt()\n",
        "        context_block = self._build_context_block(retrieved)\n",
        "        prompt = \"You are a helpful assistant that answers using ONLY the provided context.\\\\n\"\n",
        "        prompt += \"Cite sources inline like [1], [2], etc. Include a 'Sources' list at the end.\\\\n\\\\n\"\n",
        "        if memory_block:\n",
        "            prompt += f\"Conversation memory:\\\\n{memory_block}\\\\n\\\\n\"\n",
        "        if context_block:\n",
        "            prompt += f\"Context:\\\\n{context_block}\\\\n\\\\n\"\n",
        "        prompt += f\"User question:\\\\n{user_query}\\\\n\\\\n\"\n",
        "        return prompt\n",
        "\n",
        "    def answer(self, user_query: str, k: Optional[int] = None) -> Dict[str, Any]:\n",
        "        k = k or self.top_k\n",
        "        if len(user_query.strip().split()) <= 2:\n",
        "            clar_prompt = f\"User asked: '{user_query}'. Suggest 1-2 clarifying questions.\"\n",
        "            clar_question = self.generator.generate(clar_prompt, max_tokens=60, temperature=0.7)\n",
        "            self.memory.add_turn(\"assistant\", clar_question, [])\n",
        "            return {\"clarify\": True, \"clarification\": clar_question, \"sources\": []}\n",
        "        retrieved = self.store.search(user_query, top_k=k)\n",
        "        self.memory.add_turn(\"user\", user_query, [r[\"id\"] for r in retrieved])\n",
        "        prompt = self._build_prompt(user_query, retrieved)\n",
        "        gen_text = self.generator.generate(prompt, max_tokens=512)\n",
        "        self.memory.add_turn(\"assistant\", gen_text, [r[\"id\"] for r in retrieved])\n",
        "        citations = [{\"rank\": i, \"id\": r[\"id\"], \"source_id\": r[\"metadata\"].get(\"source_id\"), \"score\": r[\"score\"], \"snippet\": r[\"text\"][:300]} for i, r in enumerate(retrieved, start=1)]\n",
        "        return {\"clarify\": False, \"answer\": gen_text, \"citations\": citations, \"retrieved_count\": len(retrieved)}\n",
        "\n",
        "def load_text_file(path: str) -> str:\n",
        "    return Path(path).read_text(encoding=\"utf8\")\n",
        "\n",
        "def ingest_folder_texts(folder: str, store: DocumentStore):\n",
        "    folder = Path(folder)\n",
        "    docs = []\n",
        "    for p in folder.glob(\"**/*\"):\n",
        "        if p.is_file() and p.suffix.lower() in [\".txt\", \".md\"]:\n",
        "            docs.append((p.stem, load_text_file(str(p)), {\"path\": str(p)}))\n",
        "    store.add_documents(docs)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\" RAG Chatbot module loaded. Use quick_demo_local() or Streamlit interface to test.\")\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "PMiMG8M3yGna"
      },
      "id": "PMiMG8M3yGna",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\" Open this link:\", public_url)\n",
        "\n",
        "!streamlit run app.py --server.port 8501 --server.enableCORS false --server.enableXsrfProtection false\n"
      ],
      "metadata": {
        "id": "lZwhKw5NyIEK",
        "outputId": "1daab2aa-2ca8-4fc9-d5ec-471dc2310112",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lZwhKw5NyIEK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Open this link: NgrokTunnel: \"https://joana-pneumatophorous-semblably.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.169.180.13:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-10-30 20:29:12.240785: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761856152.283528    8281 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761856152.297547    8281 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761856152.337168    8281 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761856152.337233    8281 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761856152.337238    8281 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761856152.337242    8281 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-30 20:29:12.347565: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "config.json: 100% 665/665 [00:00<00:00, 3.59MB/s]\n",
            "model.safetensors: 100% 548M/548M [00:04<00:00, 124MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 816kB/s]\n",
            "tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 153kB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 7.93MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 3.63MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 7.44MB/s]\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4GJEDEbvyMby"
      },
      "id": "4GJEDEbvyMby",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}