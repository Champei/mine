{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Champei/mine/blob/main/task2/jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. INSTALL\n",
        "\n",
        "!pip install torch torchaudio torchvision transformers tqdm matplotlib\n"
      ],
      "metadata": {
        "id": "M8t5ZYzPWGpL",
        "outputId": "0c753753-f405-4f5d-e658-2ed4c8ad4315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "M8t5ZYzPWGpL",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. MOUNT GOOGLE DRIVE & VERIFY DATA\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "BASE_PATH = '/content/drive/MyDrive/Audios'\n",
        "\n",
        "print(\"Subfolders (categories):\", os.listdir(BASE_PATH))\n"
      ],
      "metadata": {
        "id": "_9db38oiW1eT",
        "outputId": "2764b125-62bc-499c-b3c7-b100eca513dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_9db38oiW1eT",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Subfolders (categories): ['HORN', 'INSTRUMENT', 'FOREST']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. IMPORTS & DATASET CLASS\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchaudio, random, matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "class TrainAudioSpectrogramDataset(Dataset):\n",
        "    \"\"\"Loads .wav files, converts to log-mel spectrograms, returns tensor + one-hot label.\"\"\"\n",
        "    def __init__(self, root_dir, categories, max_frames=512, fraction=1.0):\n",
        "        self.root_dir, self.categories, self.max_frames = root_dir, categories, max_frames\n",
        "        self.file_list = []\n",
        "        self.class_to_idx = {cat: i for i, cat in enumerate(categories)}\n",
        "\n",
        "        for cat in categories:\n",
        "            path = os.path.join(root_dir, cat)\n",
        "            files = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.wav')]\n",
        "            n = int(len(files) * fraction)\n",
        "            for f in random.sample(files, n):\n",
        "                self.file_list.append((f, self.class_to_idx[cat]))\n",
        "\n",
        "    def __len__(self): return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.file_list[idx]\n",
        "        wav, sr = torchaudio.load(path)\n",
        "        if wav.size(0) > 1: wav = wav.mean(0, keepdim=True)\n",
        "        mel = torchaudio.transforms.MelSpectrogram(sr, n_fft=1024, hop_length=256, n_mels=128)(wav)\n",
        "        logmel = torch.log1p(mel)\n",
        "        _, _, n_frames = logmel.shape\n",
        "        logmel = F.pad(logmel, (0, max(0, 512 - n_frames)))[:, :, :512]\n",
        "        y = F.one_hot(torch.tensor(label), num_classes=len(self.categories)).float()\n",
        "        return logmel, y\n"
      ],
      "metadata": {
        "id": "tomGOun8YIzZ"
      },
      "id": "tomGOun8YIzZ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. MODELS\n",
        "\n",
        "class CGAN_Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.latent_dim, self.num_classes = latent_dim, num_classes\n",
        "        self.fc = nn.Linear(latent_dim + num_classes, 256 * 8 * 32)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256,128,4,2,1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128,64,4,2,1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64,32,4,2,1), nn.BatchNorm2d(32), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32,1,4,2,1), nn.ReLU()\n",
        "        )\n",
        "    def forward(self,z,y):\n",
        "        h=torch.cat([z,y],1)\n",
        "        h=self.fc(h).view(-1,256,8,32)\n",
        "        return self.net(h)\n",
        "\n",
        "class CGAN_Discriminator(nn.Module):\n",
        "    def __init__(self,num_classes):\n",
        "        super().__init__()\n",
        "        self.label_emb=nn.Linear(num_classes,128*512)\n",
        "        self.net=nn.Sequential(\n",
        "            nn.Conv2d(2,32,4,2,1), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32,64,4,2,1), nn.BatchNorm2d(64), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64,128,4,2,1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128,256,4,2,1), nn.BatchNorm2d(256), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(256,1,(8,32),1,0)\n",
        "        )\n",
        "    def forward(self,x,y):\n",
        "        ymap=self.label_emb(y).view(-1,1,128,512)\n",
        "        h=torch.cat([x,ymap],1)\n",
        "        return self.net(h).view(-1,1)\n"
      ],
      "metadata": {
        "id": "fcdl1JOcaEl5"
      },
      "id": "fcdl1JOcaEl5",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. UTILITIES FOR AUDIO GENERATION & PLAYBACK\n",
        "\n",
        "def generate_audio_gan(generator, category_idx, num_samples, device, sr=22050):\n",
        "    generator.eval()\n",
        "    y = F.one_hot(torch.tensor([category_idx]), num_classes=generator.num_classes).float().to(device)\n",
        "    z = torch.randn(num_samples, generator.latent_dim, device=device)\n",
        "    with torch.no_grad():\n",
        "        logmel = generator(z, y)\n",
        "    mel = torch.expm1(logmel).squeeze(1)\n",
        "    invmel = torchaudio.transforms.InverseMelScale(n_stft=513, n_mels=128, sample_rate=sr).to(device)\n",
        "    spec = invmel(mel)\n",
        "    griffin = torchaudio.transforms.GriffinLim(1024, hop_length=256, n_iter=32).to(device)\n",
        "    wav = griffin(spec).cpu()\n",
        "    return wav\n",
        "\n",
        "def play_and_save(wav, sr, name):\n",
        "    import torchaudio\n",
        "    torchaudio.save(name, wav.squeeze(0), sr)\n",
        "    print(\"Saved:\", name)\n",
        "    display(Audio(wav.numpy().squeeze(), rate=sr))\n"
      ],
      "metadata": {
        "id": "358iVK8oaSF8"
      },
      "id": "358iVK8oaSF8",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. TRAINING FUNCTION\n",
        "\n",
        "def train_gan(generator, discriminator, dataloader, device, categories, epochs, lr, latent_dim):\n",
        "\n",
        "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    os.makedirs(\"gan_spectrogram_plots\", exist_ok=True)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        loop = tqdm(dataloader, desc=f\"Epoch {epoch}/{epochs}\", leave=True)\n",
        "\n",
        "        for real_specs, labels in loop:\n",
        "            real_specs = real_specs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            batch_size = real_specs.size(0)\n",
        "\n",
        "            real_labels = torch.ones(batch_size, 1, device=device)\n",
        "            fake_labels = torch.zeros(batch_size, 1, device=device)\n",
        "\n",
        "            # Train Discriminator\n",
        "\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            real_out = discriminator(real_specs, labels)\n",
        "            loss_D_real = criterion(real_out, real_labels)\n",
        "\n",
        "            z = torch.randn(batch_size, latent_dim, device=device)\n",
        "            fake_specs = generator(z, labels)\n",
        "\n",
        "            fake_out = discriminator(fake_specs.detach(), labels)\n",
        "            loss_D_fake = criterion(fake_out, fake_labels)\n",
        "\n",
        "            loss_D = loss_D_real + loss_D_fake\n",
        "            loss_D.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Train Generator\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            fake_out = discriminator(fake_specs, labels)\n",
        "            loss_G = criterion(fake_out, real_labels)\n",
        "\n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            loop.set_postfix(lossD=loss_D.item(), lossG=loss_G.item())\n",
        "\n",
        "        print(f\"\\nSample generation after epoch {epoch}\")\n",
        "\n",
        "        generator.eval()\n",
        "\n",
        "        for cat_idx, cat_name in enumerate(categories):\n",
        "            y_cond = F.one_hot(torch.tensor([cat_idx]), num_classes=generator.num_categories).float().to(device)\n",
        "            z_sample = torch.randn(1, generator.latent_dim).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                spec_log = generator(z_sample, y_cond).squeeze().cpu().numpy()\n",
        "\n",
        "            plt.figure(figsize=(6,4))\n",
        "            plt.imshow(spec_log, aspect='auto', origin='lower', cmap='viridis')\n",
        "            plt.title(f\"{cat_name} (Epoch {epoch})\")\n",
        "            plt.axis('off')\n",
        "            plt.savefig(f\"gan_spectrogram_plots/{cat_name}_ep{epoch}.png\")\n",
        "            plt.close()\n",
        "\n",
        "        generator.train()\n",
        "\n"
      ],
      "metadata": {
        "id": "znISdU_SaZAk"
      },
      "id": "znISdU_SaZAk",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install ffmpeg -y\n"
      ],
      "metadata": {
        "id": "5jugQX5XbKEF",
        "outputId": "3a960674-fd9b-4bc5-bb51-d138b40593a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5jugQX5XbKEF",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Audios'\n",
        "\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    for f in files:\n",
        "        if f.lower().endswith('.mp3'):\n",
        "            mp3_path = os.path.join(root, f)\n",
        "            wav_path = os.path.splitext(mp3_path)[0] + '.wav'\n",
        "\n",
        "            # Only convert if WAV doesn't exist yet\n",
        "            if not os.path.exists(wav_path):\n",
        "                print(f\"Converting: {mp3_path}\")\n",
        "                !ffmpeg -y -i \"{mp3_path}\" -ar 22050 -ac 1 \"{wav_path}\"\n"
      ],
      "metadata": {
        "id": "_vk1cX6DbZ4z"
      },
      "id": "_vk1cX6DbZ4z",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cat in os.listdir(base_dir):\n",
        "    cat_path = os.path.join(base_dir, cat)\n",
        "    if os.path.isdir(cat_path):\n",
        "        wavs = [f for f in os.listdir(cat_path) if f.endswith('.wav')]\n",
        "        print(f\"{cat}: {len(wavs)} wav files\")\n"
      ],
      "metadata": {
        "id": "GwKaLtGxbcf5",
        "outputId": "7cd27cb2-6bd8-447b-9370-a354dffa9498",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GwKaLtGxbcf5",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HORN: 5 wav files\n",
            "INSTRUMENT: 5 wav files\n",
            "FOREST: 5 wav files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LATENT_DIM = 100\n",
        "EPOCHS = 5\n",
        "BATCH = 8\n",
        "LR = 2e-4"
      ],
      "metadata": {
        "id": "Tz5-19d6biPK"
      },
      "id": "Tz5-19d6biPK",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/Audios'\n",
        "cats = sorted([d for d in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, d))])\n",
        "print(\"Categories:\", cats)\n",
        "\n",
        "ds = TrainAudioSpectrogramDataset(train_path, cats)\n",
        "dl = DataLoader(ds, batch_size=BATCH, shuffle=True, num_workers=2)\n",
        "\n",
        "G = CGAN_Generator(LATENT_DIM, len(cats)).to(DEVICE)\n",
        "D = CGAN_Discriminator(len(cats)).to(DEVICE)\n",
        "\n",
        "train_gan(G, D, dl, DEVICE, cats, EPOCHS, LR, LATENT_DIM)\n"
      ],
      "metadata": {
        "id": "JL_lNQw2bf1M"
      },
      "id": "JL_lNQw2bf1M",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}